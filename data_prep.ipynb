{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T13:46:40.585687Z",
     "start_time": "2025-08-19T13:46:37.293709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import json\n",
    "\n",
    "from mepylome import CNV, MethylData, ReferenceMethylData\n",
    "from mepylome.analysis import MethylAnalysis\n",
    "import os"
   ],
   "id": "dd4f8b5e1fd4ba22",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T13:46:40.722820Z",
     "start_time": "2025-08-19T13:46:40.612721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "with open('data/EPIC_v1_EPIC_v2_common_features.csv') as f:\n",
    "    EPIC_v1_EPIC_v2_common_features = json.load(f)"
   ],
   "id": "e123c90d96140ac3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T13:46:40.747342Z",
     "start_time": "2025-08-19T13:46:40.743359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_matching_filename(basename, idat_dir):\n",
    "    for file in os.listdir(idat_dir):\n",
    "        if basename in file:\n",
    "            return file.replace('_Grn.idat', '').replace('_Red.idat', '')\n",
    "    return basename\n"
   ],
   "id": "e56280b085ba766f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Extract beta values from idat",
   "id": "794c9086e2cca3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T13:47:47.148008Z",
     "start_time": "2025-08-19T13:47:47.132727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_anno = pd.read_csv('data/all_sample_anno.csv')\n",
    "idat_dir_EPIC = 'data/EPIC/'\n",
    "idat_dir_EPICv2 = 'data/EPICv2/'\n",
    "\n",
    "# Filter for EPIC in column Platform\n",
    "anno_epic = data_anno[data_anno['Platform'] == 'EPIC']\n",
    "anno_epic_v2 = data_anno[data_anno['Platform'] == 'EPICv2']"
   ],
   "id": "97468c2cbffa054",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T14:22:01.066324Z",
     "start_time": "2025-07-15T14:20:14.177071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load EPIC list\n",
    "basename_epic = anno_epic['Basename'].tolist()\n",
    "list_epic = []\n",
    "for i in basename_epic:\n",
    "    list_epic.append(f'{idat_dir_EPIC}/{get_matching_filename(i, idat_dir_EPIC)}')\n",
    "\n",
    "# Load EPIC betas\n",
    "betas_epic = MethylData(file=list_epic, prep=\"noob\").betas.loc[EPIC_v1_EPIC_v2_common_features]\n"
   ],
   "id": "e6de38b978c2680a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T13:48:28.333380Z",
     "start_time": "2025-08-19T13:47:51.510521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load EPIC list\n",
    "basename_epic_v2 = anno_epic_v2['Basename'].tolist()\n",
    "list_epic_v2 = []\n",
    "for i in basename_epic_v2:\n",
    "    list_epic_v2.append(f'{idat_dir_EPICv2}/{get_matching_filename(i, idat_dir_EPICv2)}')\n",
    "\n",
    "# Load EPIC betas\n",
    "betas_epic_v2 = MethylData(file=list_epic_v2, prep=\"noob\").betas.loc[EPIC_v1_EPIC_v2_common_features]\n"
   ],
   "id": "20970a18d999d81d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T13:51:08.133474Z",
     "start_time": "2025-08-19T13:51:07.866103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# remove duplicate index values\n",
    "betas_epic = betas_epic.loc[~betas_epic.index.duplicated(keep='first')]\n",
    "betas_epic_v2 = betas_epic_v2.loc[~betas_epic_v2.index.duplicated(keep='first')]\n"
   ],
   "id": "83e020669961b261",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T13:53:21.051644Z",
     "start_time": "2025-08-19T13:53:20.070773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Combine the EPIC and EPICv2 betas keeping common rows\n",
    "all_beta_values = pd.concat([betas_epic, betas_epic_v2], axis=1, join='inner')\n",
    "all_beta_values = all_beta_values.loc[~all_beta_values.index.duplicated(keep='first')]\n",
    "all_beta_values.shape"
   ],
   "id": "b76ce28687679dd0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(671727, 114)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T13:54:51.225190Z",
     "start_time": "2025-08-19T13:54:06.188525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save to file\n",
    "all_beta_values.to_csv('data/all_beta_values.csv')"
   ],
   "id": "d4973459f3daac2a",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Get Features",
   "id": "60964def04c3be51"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:05:04.413836Z",
     "start_time": "2025-08-19T14:04:56.522983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load annotation\n",
    "step_1_anno = pd.read_csv('data/step_1_training_anno.csv', index_col=0)\n",
    "step_2_anno = pd.read_csv('data/step_2_training_anno.csv', index_col=0)\n",
    "step_3_anno = pd.read_csv('data/step_3_training_anno.csv', index_col=0)\n",
    "testing_anno = pd.read_csv('data/testing_set_anno.csv', index_col=0)\n",
    "\n",
    "# Filter betas\n",
    "step_1_betas = all_beta_values[step_1_anno['Sample_Name'].tolist()]\n",
    "step_2_betas = all_beta_values[step_2_anno['Sample_Name'].tolist()]\n",
    "step_3_betas = all_beta_values[step_3_anno['Sample_Name'].tolist()]\n",
    "testing_betas = all_beta_values[testing_anno['Sample_Name'].tolist()]"
   ],
   "id": "a03d4bb38cbf87ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(671727, 114)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# keep only top 5000 rows with highest std\n",
    "def filter_top_std(betas, n):\n",
    "    betas['row_std'] = betas.std(axis=1)\n",
    "    betas = betas.sort_values(by='row_std', ascending=False)\n",
    "    betas = betas.head(n)\n",
    "    return betas\n",
    "\n",
    "def filter_high_corr(betas, corr_threshold, label):\n",
    "    # Compute Mutual Information\n",
    "    mi_scores = mutual_info_classif(betas, label, random_state=42)\n",
    "    mi_values = {}\n",
    "    for i in range(len(betas.columns.tolist())):\n",
    "        mi_values[betas.columns.tolist()[i]] = mi_scores[i]\n",
    "        i += 1\n",
    "\n",
    "    # Filter features with high correlation to each other\n",
    "    correlation_matrix = betas.corr().abs()\n",
    "\n",
    "    # Find feature pairs with correlation above 0.9\n",
    "    high_corr_pairs = np.where((np.abs(correlation_matrix) > corr_threshold) & (np.abs(correlation_matrix) < 1.0))\n",
    "\n",
    "    # Create a set to track features to drop\n",
    "    features_to_drop = set()\n",
    "\n",
    "    # Iterate through pairs and drop the feature with lower standard deviation\n",
    "    for i, j in zip(*high_corr_pairs):\n",
    "        feature1 = correlation_matrix.columns[i]\n",
    "        feature2 = correlation_matrix.columns[j]\n",
    "        if feature1 not in features_to_drop and feature2 not in features_to_drop:\n",
    "            # Compare standard deviations and drop the lower one\n",
    "            if mi_values[feature1] > mi_values[feature2]:\n",
    "                features_to_drop.add(feature2)\n",
    "            else:\n",
    "                features_to_drop.add(feature1)\n",
    "\n",
    "    # Drop features\n",
    "    betas_filtered = betas.drop(columns=features_to_drop)\n",
    "\n",
    "    return betas_filtered"
   ],
   "id": "15131d8e9afd8ed8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# filter top 5000 rows with highest std\n",
    "top_5000_std_step_1 = filter_top_std(step_1_betas, 5000)\n",
    "top_5000_std_step_2 = filter_top_std(step_2_betas, 5000)\n",
    "top_5000_std_step_3 = filter_top_std(step_3_betas, 5000)\n",
    "\n",
    "# filter high correlation\n",
    "top_5000_std_step_1_filtered = filter_high_corr(top_5000_std_step_1, 0.9, step_1_anno['Label_PMOC'])\n",
    "top_5000_std_step_2_filtered = filter_high_corr(top_5000_std_step_2, 0.9, step_2_anno['Label_SMOC'])\n",
    "top_5000_std_step_3_filtered = filter_high_corr(top_5000_std_step_3, 0.9, step_3_anno['Label_STAD_COAD'])\n",
    "\n",
    "testing_betas_filtered_step_1 = testing_betas.loc[top_5000_std_step_1_filtered.index.tolist()]\n",
    "testing_betas_filtered_step_2 = testing_betas.loc[top_5000_std_step_2_filtered.index.tolist()]\n",
    "testing_betas_filtered_step_3 = testing_betas.loc[top_5000_std_step_3_filtered.index.tolist()]\n",
    "\n",
    "# extract features\n",
    "feature_cpg_list_step_1 = top_5000_std_step_1_filtered.index.tolist()\n",
    "feature_cpg_list_step_2 = top_5000_std_step_2_filtered.index.tolist()\n",
    "feature_cpg_list_step_3 = top_5000_std_step_3_filtered.index.tolist()\n",
    "\n",
    "# Save to file\n",
    "top_5000_std_step_1_filtered.to_csv('data/top_5000_std_step_1_filtered.csv')\n",
    "top_5000_std_step_2_filtered.to_csv('data/top_5000_std_step_2_filtered.csv')\n",
    "top_5000_std_step_3_filtered.to_csv('data/top_5000_std_step_3_filtered.csv')\n",
    "\n",
    "testing_betas_filtered_step_1.to_csv('data/testing_betas_filtered_step_1.csv')\n",
    "testing_betas_filtered_step_2.to_csv('data/testing_betas_filtered_step_2.csv')\n",
    "testing_betas_filtered_step_3.to_csv('data/testing_betas_filtered_step_3.csv')\n",
    "\n",
    "with open('data/feature_cpg_list_step_1.json', 'wb') as f:\n",
    "    json.dump(feature_cpg_list_step_1, f)\n",
    "\n",
    "with open('data/feature_cpg_list_step_2.json', 'wb') as f:\n",
    "    json.dump(feature_cpg_list_step_2, f)\n",
    "\n",
    "with open('data/feature_cpg_list_step_3.json', 'wb') as f:\n",
    "    json.dump(feature_cpg_list_step_3, f)"
   ],
   "id": "3b08fb309cfc4ecf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
